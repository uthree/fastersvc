### 本リポジトリの技術的な詳細 (WIP)
将来的に何らかの形で発表や論文の執筆をしたいので、それに近い内容で本リポジトリでの成果物について詳細に説明する。論文の下書きのような何かである。技術的なことに興味がない人はこのドキュメントを読む必要性はないかもしれない。

# FasterSVC : 蒸留モデルとk近傍法に基づく高速な声質変換の開発
著者: uthree

## 1. はじめに
声質変換とは、発話内容などの言語的な特徴を維持したまま、話者や感情などのスタイル情報のみを変更した新たな音声を得るタスクである。これにより、肉体の制約を超えた発声が可能になるため、エンターテインメントの分野で有用であると考えられる。しかし、従来の手法では多くの計算資源が必要だったり、大きな遅延が発生してしまい、会話に用いることが困難であったり、音高、抑揚などの言語的な情報が損なわれてしまったりなどの問題が残されていた。本研究ではそれらの問題に対処する声質変換手法を提案する。

## 2. 手法

### 2.1. モチベーション
VRChatは、VR機器を用いて、ゲーム内のキャラクター(アバター)の主観視点で腕や頭を動かすジェスチャーを用いながら会話したり、バーチャル空間内の物体を使ってゲームを遊んだりすることができるプラットフォームである。
主観視点であることにより、まるでアバターそのものになったかのような体験をすることができ、現実の肉体の制約を超えた表現やコミュニケーションが可能である。
このプラットフォームにはボイスチャットの機能が搭載されており、アバターを利用したまま音声通話をすることが可能である。
しかし、例えば、女性のアバターを使用しているが実際の利用者は男性である場合、会話をした際に姿は女性であるが聞こえてくる声がそのまま男性のものであるという現象当然ながら発生する。
この外見と声の乖離を解決するために、声質変換を行うソフトウェア(ボイスチェンジャー)を使用して解決を図る利用者もいるが、従来のボイスチェンジャーはTD-PSOLAやPhase Vocoderを使用した手法であり、機械的に音高(ピッチ)を上げるだけである。そのため、実際の人間の声とは異なる声であったり、これらの手法特有のノイズが発生してしまう場合がある。また、その性質上元の声質に大きく左右され、任意の声質に変換できるというわけではない。
一方、RVC(Retrieval Based Voice Conversion) や MMVC(Many-to-Many Voice Conversion)などの深層学習を用いた声質変換手法では、前述の問題を解決することができるが、GPU(Graphic Processing Unit)を用いた大規模な数値計算を必要とするため、リアルタイムの3Dレンダリングを必要とするVRChatとの同時使用は、非常に高性能なコンピュータを必要とするため敷居が高い。
また、これらの手法はHifi-GANをベースとした音声合成を行っているため、未来の情報を参照して音声を合成する都合上、音声合成が遅延してしまう。別の手法としてkNN-VCがあげられるが、これは抑揚がくずれてしまい、言語的な意味が損なわれてしまう可能性がある。
これらの問題を解決するため、本研究では、抑揚がくずれず、低遅延で軽量な深層学習ベースの声質変換手法を提案する。

### 2.1. 提案手法

## 参考文献
- [kNN-VC](https://arxiv.org/abs/2305.18975)
- [WavLM](https://arxiv.org/abs/2110.13900)
- [Hifi-GAN](https://arxiv.org/abs/2010.05646)
- [VRChat 公式サイト](https://hello.vrchat.com/)
- [VRChat Wikipedia](https://ja.wikipedia.org/wiki/VRChat)
- [恋声](http://koigoemoe.g2.xrea.com/koigoe/koigoe.html)
- [RVC Retrieval Based Voice Conversion](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI)
- [VC Client](https://github.com/w-okada/voice-changer)
- [MMVC Many-to-Many Voice Conversion](https://github.com/isletennos/MMVC_Trainer)