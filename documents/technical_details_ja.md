### 本リポジトリの技術的な詳細 (WIP)
将来的に何らかの形で発表や論文の執筆をしたいので、それに近い内容で本リポジトリでの成果物について詳細に説明する。論文の下書きのような何かである。技術的なことに興味がない人はこのドキュメントを読む必要性はないかもしれない。

# FasterSVC : HuBERTの蒸留とNSFモデルによる高速な声質変換の開発
著者: uthree

## 1.1 はじめに
声質変換とは、発話内容などの言語的な特徴を維持したまま、話者や感情などのスタイル情報のみを変更した新たな音声を得るタスクである。これにより、肉体の制約を超えた発声が可能になるため、エンターテインメントの分野で有用であると考えられる。しかし、従来の手法では多くの計算資源が必要だったり、大きな遅延が発生してしまい、会話に用いることが困難であったり、音高、抑揚などの言語的な情報が損なわれてしまったりなどの問題が残されていた。
また、それらを解決した手法は存在するが、多くの計算資源を必要とするため、ゲームなどの重たい処理と同時実行は難しい。本研究では、それらの問題に対処する声質変換手法を提案する。

### 1.2 モチベーション
[VRChat](https://hello.vrchat.com/)は、VR機器を用いて、ゲーム内のキャラクター(アバター)の主観視点で腕や頭を動かすジェスチャーを用いながら会話したり、バーチャル空間内の物体を使ってゲームを遊んだりすることができるプラットフォームである。
主観視点であることにより、まるでアバターそのものになったかのような体験をすることができ、現実の肉体の制約を超えた表現やコミュニケーションが可能である。
このプラットフォームにはボイスチャットの機能が搭載されており、アバターを利用したまま音声通話をすることが可能である。
しかし、例えば、女性のアバターを使用しているが実際の利用者は男性である場合、会話をした際に姿は女性であるが聞こえてくる声がそのまま男性のものであるという現象当然ながら発生する。
この外見と声の乖離を解決するために、声質変換を行うソフトウェア(ボイスチェンジャー)を使用して解決を図る利用者もいるが、[恋声](http://koigoemoe.g2.xrea.com/koigoe/koigoe.html)などの従来のボイスチェンジャーはTD-PSOLAやPhase Vocoderを使用した手法であり、機械的に音高(ピッチ)を上げるだけである。そのため、実際の人間の声とは異なる声であったり、これらの手法特有のノイズが発生してしまう場合がある。また、その性質上元の声質に大きく左右され、任意の声質に変換できるというわけではない。
一方、[RVC](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI)(Retrieval Based Voice Conversion) や [MMVC](https://github.com/isletennos/MMVC_Trainer)(Many-to-Many Voice Conversion)などの深層学習を用いた声質変換手法では、前述の問題を解決することができるが、GPU(Graphic Processing Unit)を用いた大規模な数値計算を必要とするため、リアルタイムの3Dレンダリングを必要とするVRChatとの同時使用は、非常に高性能なコンピュータを必要とするため敷居が高い。
また、これらの手法は[HiFi-GAN](https://arxiv.org/abs/2010.05646)をベースとした音声合成を行っているため、未来の情報を参照して音声を合成する都合上、音声合成が遅延してしまう。別の手法として[kNN-VC](https://arxiv.org/abs/2305.18975)があげられるが、これは抑揚がくずれてしまい、言語的な意味が損なわれてしまう可能性がある。また、kNN-VCはHiFi-GANを使用しているため重たいという問題点も残っている。
これらの問題を解決するため、本研究では、抑揚がくずれず、低遅延で軽量な深層学習ベースの声質変換手法を提案する。

## 2. 提案手法
### 2.1. HuBERT-Softの蒸留
[SoftVC](https://arxiv.org/abs/2111.02392)は、HuBERT-Softを使って疑似的な音素情報を取得する。しかし、HuBERT-SoftはHuBERTに基づいているため、Self-Attention層を含む。そのため、系列長に対して二次関数的に計算量やメモリ使用量が増加する。また、双方向の注意が可能な構造となっているため、リアルタイムで低遅延に変換する際に使用するには不向きである。そのため、このモデルを未来の情報を産使用しない"Causal"な1次元CNNで蒸留したものを用いる。このリポジトリでは、Dilation Rateを変更した[ConvNeXt](https://arxiv.org/abs/2201.03545)レイヤーのスタックを使用している。

### 2.2. 高速なピッチ推定器
ソースフィルタモデルに基づくニューラルボコーダーを学習する際、通常であればWORLDを用いて基音周波数(ピッチ)を推定するが、この処理は並列化されておらず、時間がかかるため、リアルタイム処理には不向きである。よって、本リポジトリではHuBERT-Softと同様に、Dilation Rateを変更したConvNeXtレイヤーのスタックでharvestによるピッチ推定を蒸留する。

### 2.3. ソースフィルタモデルに基づくデコーダー
ソースフィルタモデルは、基音周波数をもとに正弦波等の単純な信号を生成し(ソース)、それを1次元のU-Net等で加工するという方式の音声合成手法である。この手法を用いることで、安定したピッチ制御が可能になる。

## 参考文献
- [VRChat 公式サイト](https://hello.vrchat.com/)
- [VRChat Wikipedia](https://ja.wikipedia.org/wiki/VRChat)
- [恋声](http://koigoemoe.g2.xrea.com/koigoe/koigoe.html)
- [RVC Retrieval Based Voice Conversion](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI)
- [VC Client](https://github.com/w-okada/voice-changer)
- [MMVC Many-to-Many Voice Conversion](https://github.com/isletennos/MMVC_Trainer)
- [HiFi-GAN](https://arxiv.org/abs/2010.05646)
- [kNN-VC](https://arxiv.org/abs/2305.18975)
- [SoftVC](https://arxiv.org/abs/2111.02392)
- [ConvNeXt](https://arxiv.org/abs/2201.03545)